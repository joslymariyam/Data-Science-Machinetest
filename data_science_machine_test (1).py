# -*- coding: utf-8 -*-
"""Data science machine test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uhPYIhnzgG8gjX6gCTSOpX2mkax_eRX_
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.preprocessing.text import Tokenizer
import joblib

from google.colab import drive
drive.mount('/content/drive')

df  = pd.read_csv('/content/drive/MyDrive/mydataset/emails.csv')
df

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Load the dataset into a pandas DataFrame
# Assuming your DataFrame is named 'df'
# Make sure the first column contains the subject of the email and the second column contains the label (0 for spam, 1 for not spam)

# Split the data into features and labels
X = df.iloc[:, 0]  # Subject of the email
y = df.iloc[:, 1]  # Spam or not spam label

# Convert labels to numeric form
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Tokenize the text data
tokenizer = tf.keras.preprocessing.text.Tokenizer()
tokenizer.fit_on_texts(X_train)

joblib.dump(tokenizer, 'tokenizer.joblib')


X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

# Pad sequences to ensure uniform length
max_length = 100  # Choose a suitable length based on your dataset
X_train_pad = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_length, padding='post')
X_test_pad = tf.keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_length, padding='post')

# Define the model architecture
model = Sequential([
    Dense(64, activation='relu', input_shape=(max_length,)),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train_pad, y_train, epochs=10, batch_size=64, validation_data=(X_test_pad, y_test))

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

y_pred_probs = model.predict(X_test_pad)

y_pred = (y_pred_probs > 0.5).astype("int32")

y_pred = y_pred.ravel()

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

conf_matrix = confusion_matrix(y_test, y_pred)

print("Evaluation Metrics:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("\nConfusion Matrix:")
print(conf_matrix)

import joblib

# Save the trained model
joblib.dump(model, 'email_spam_classifier_model.joblib')

model.save('email_spam_classifier_model.h5')

pip install fastapi uvicorn

!pip install fastapi uvicorn pyngrok

!pip install nest_asyncio

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
import joblib
from pyngrok import ngrok
import uvicorn
import nest_asyncio

# Apply the patch to allow nested use of asyncio.run
nest_asyncio.apply()

app = FastAPI()

# Load the saved model
model = tf.keras.models.load_model('email_spam_classifier_model.h5')

# Load the tokenizer
tokenizer = joblib.load('tokenizer.joblib')

class Email(BaseModel):
    subject: str

@app.post("/predict/")
def predict(email: Email):
    # Preprocess the email subject
    seq = tokenizer.texts_to_sequences([email.subject])
    padded = pad_sequences(seq, maxlen=100, padding='post')

    # Make prediction
    pred = model.predict(padded)
    is_spam = int(pred[0][0] > 0.5)  # Convert numpy.int64 to Python int

    # Return the result
    return {"subject": email.subject, "is_spam": is_spam}

# Set up ngrok with your authtoken
ngrok.set_auth_token('2faEbUjpPvFODS5rZS3UBVPA3wL_6At8JqgS6iC35kwMmX9UR')

# Start an ngrok tunnel to the uvicorn server
tunnel = ngrok.connect(8001)
print('Public URL:', tunnel.public_url)

# Use uvicorn to run the app, specifying host and port
uvicorn.run(app, host="127.0.0.1", port=8001)